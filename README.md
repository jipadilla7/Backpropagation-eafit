# Neural Networks: Forward & Backward Propagation, Gradients, and Practical Exercises

## Jorge Iván Padilla Buriticá, PhD.
### 2025
**Contact:** [jorgeivanpb@gmail.com](mailto:jorgeivanpb@gmail.com)

---

## Repository Overview
This repository provides comprehensive resources designed to help learners master the concepts of **forward propagation**, **backpropagation**, **gradient computation**, and **gradient descent optimization** in neural networks. It includes detailed explanations, practical Python code examples, mathematical analyses, and structured exercises to enhance understanding and practical skills.

---

## Contents
- **Forward Propagation:** Detailed implementation examples demonstrating how inputs are processed through neural networks to generate outputs.
- **Backward Propagation (Backpropagation):** Clear explanations and implementations of gradient calculation, enabling effective learning and adjustment of network weights.
- **Gradient Analysis:** Mathematical interpretations of gradients, their behaviors, stability concerns, and practical implications for training neural networks.
- **Practical Exercises:** Carefully designed exercises with specific functions, guiding users through the implementation, mathematical analysis, interpretation of gradients, and weight updates.

### Featured Exercises:
- **Exercise 1:** \( f(x, y, z) = \frac{x + y}{z} \)
- **Exercise 2:** \( f(x, y, z) = x e^{y} + \sin(z) \)
- **Exercise 3:** \( f(x, y) = \log(x^{2} + y^{2} + 1) \)

Each exercise includes:
- Step-by-step instructions for implementation in Python.
- Example inputs for testing and validation.
- Critical mathematical questions to explore gradient behaviors and stability.
- Practical guidance on updating weights using gradients and optimizing neural network performance.

---

## How to Use This Repository
1. **Explore**: Review the detailed explanations in each section.
2. **Implement**: Follow the instructions and use example inputs to practice forward and backward propagation.
3. **Analyze**: Engage with mathematical questions to deepen your understanding of neural network dynamics.
4. **Optimize**: Apply the gradient descent techniques demonstrated here to enhance network training and performance.

---

This repository aims to serve as a clear, practical, and insightful guide for students, researchers, and practitioners eager to deepen their understanding of neural network concepts and improve their computational skills.

